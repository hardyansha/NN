{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with Activation Function: sigmoid\n",
      "\n",
      "Epoch 1, Loss: 0.3030, Train Acc: 91.22%, Test Acc: 91.78%\n",
      "Epoch 2, Loss: 0.2298, Train Acc: 93.35%, Test Acc: 93.34%\n",
      "Epoch 3, Loss: 0.1880, Train Acc: 94.55%, Test Acc: 94.41%\n",
      "Epoch 4, Loss: 0.1578, Train Acc: 95.39%, Test Acc: 95.10%\n",
      "Epoch 5, Loss: 0.1351, Train Acc: 96.05%, Test Acc: 95.76%\n",
      "Epoch 6, Loss: 0.1176, Train Acc: 96.62%, Test Acc: 96.18%\n",
      "Epoch 7, Loss: 0.1058, Train Acc: 96.94%, Test Acc: 96.48%\n",
      "Epoch 8, Loss: 0.0934, Train Acc: 97.33%, Test Acc: 96.79%\n",
      "Epoch 9, Loss: 0.0847, Train Acc: 97.59%, Test Acc: 96.90%\n",
      "Epoch 10, Loss: 0.0768, Train Acc: 97.80%, Test Acc: 97.12%\n",
      "\n",
      "Training with Activation Function: relu\n",
      "\n",
      "Epoch 1, Loss: 0.1755, Train Acc: 94.88%, Test Acc: 94.79%\n",
      "Epoch 2, Loss: 0.1181, Train Acc: 96.51%, Test Acc: 96.09%\n",
      "Epoch 3, Loss: 0.0914, Train Acc: 97.31%, Test Acc: 96.62%\n",
      "Epoch 4, Loss: 0.0729, Train Acc: 97.86%, Test Acc: 97.10%\n",
      "Epoch 5, Loss: 0.0611, Train Acc: 98.20%, Test Acc: 97.38%\n",
      "Epoch 6, Loss: 0.0542, Train Acc: 98.35%, Test Acc: 97.48%\n",
      "Epoch 7, Loss: 0.0464, Train Acc: 98.61%, Test Acc: 97.60%\n",
      "Epoch 8, Loss: 0.0419, Train Acc: 98.76%, Test Acc: 97.69%\n",
      "Epoch 9, Loss: 0.0368, Train Acc: 98.92%, Test Acc: 97.80%\n",
      "Epoch 10, Loss: 0.0327, Train Acc: 98.99%, Test Acc: 97.85%\n",
      "\n",
      "Training with Activation Function: tanh\n",
      "\n",
      "Epoch 1, Loss: 0.2515, Train Acc: 92.56%, Test Acc: 92.36%\n",
      "Epoch 2, Loss: 0.1948, Train Acc: 94.27%, Test Acc: 93.89%\n",
      "Epoch 3, Loss: 0.1615, Train Acc: 95.19%, Test Acc: 94.86%\n",
      "Epoch 4, Loss: 0.1386, Train Acc: 95.79%, Test Acc: 95.34%\n",
      "Epoch 5, Loss: 0.1216, Train Acc: 96.33%, Test Acc: 95.83%\n",
      "Epoch 6, Loss: 0.1061, Train Acc: 96.81%, Test Acc: 96.12%\n",
      "Epoch 7, Loss: 0.0943, Train Acc: 97.21%, Test Acc: 96.45%\n",
      "Epoch 8, Loss: 0.0859, Train Acc: 97.50%, Test Acc: 96.67%\n",
      "Epoch 9, Loss: 0.0806, Train Acc: 97.61%, Test Acc: 96.64%\n",
      "Epoch 10, Loss: 0.0722, Train Acc: 97.82%, Test Acc: 96.81%\n",
      "\n",
      "PDF Report saved successfully at: mnist_results\\MNIST_Results_Report.pdf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import os\n",
    "from fpdf import FPDF\n",
    "\n",
    "# Disable eager execution for TensorFlow 1.x compatibility\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Set output directory for saving results\n",
    "output_dir = \"mnist_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train.reshape(-1, 784) / 255.0, x_test.reshape(-1, 784) / 255.0\n",
    "y_train_one_hot = np.eye(10)[y_train]\n",
    "y_test_one_hot = np.eye(10)[y_test]\n",
    "\n",
    "# Model hyperparameters\n",
    "input_size = 784\n",
    "hidden_size = 256  # Single Hidden Layer\n",
    "output_size = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "epochs = 10  # Reduced for testing purpose\n",
    "dropout_rate = 0.5\n",
    "activations = {'sigmoid': tf.nn.sigmoid, 'relu': tf.nn.relu, 'tanh': tf.nn.tanh}\n",
    "\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "for act_name, activation in activations.items():\n",
    "    print(f\"\\nTraining with Activation Function: {act_name}\\n\")\n",
    "\n",
    "    X = tf.compat.v1.placeholder(tf.float32, [None, input_size])\n",
    "    y = tf.compat.v1.placeholder(tf.float32, [None, output_size])\n",
    "    keep_prob = tf.compat.v1.placeholder(tf.float32)\n",
    "\n",
    "    # Initialize weights and biases\n",
    "    weights = {\n",
    "        'w1': tf.Variable(tf.random.truncated_normal([input_size, hidden_size], stddev=0.1)),\n",
    "        'w2': tf.Variable(tf.random.truncated_normal([hidden_size, output_size], stddev=0.1))\n",
    "    }\n",
    "    biases = {\n",
    "        'b1': tf.Variable(tf.zeros([hidden_size])),\n",
    "        'b2': tf.Variable(tf.zeros([output_size]))\n",
    "    }\n",
    "\n",
    "    # Neural network model\n",
    "    layer1 = activation(tf.matmul(X, weights['w1']) + biases['b1'])\n",
    "    layer1_drop = tf.nn.dropout(layer1, rate=1 - keep_prob)\n",
    "    logits = tf.matmul(layer1_drop, weights['w2']) + biases['b2']\n",
    "\n",
    "    # Loss, optimizer, accuracy\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    losses, accuracies = [], []\n",
    "    start_time = time.time()\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(0, len(x_train), batch_size):\n",
    "                batch_x, batch_y = x_train[i:i+batch_size], y_train_one_hot[i:i+batch_size]\n",
    "                sess.run(optimizer, feed_dict={X: batch_x, y: batch_y, keep_prob: 1 - dropout_rate})\n",
    "\n",
    "            train_loss, train_acc = sess.run([loss, accuracy], feed_dict={X: x_train, y: y_train_one_hot, keep_prob: 1.0})\n",
    "            test_acc = sess.run(accuracy, feed_dict={X: x_test, y: y_test_one_hot, keep_prob: 1.0})\n",
    "            losses.append(train_loss)\n",
    "            accuracies.append(train_acc)\n",
    "            print(f\"Epoch {epoch+1}, Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%, Test Acc: {test_acc*100:.2f}%\")\n",
    "\n",
    "        execution_time = time.time() - start_time\n",
    "        final_test_preds = sess.run(tf.argmax(logits, 1), feed_dict={X: x_test, keep_prob: 1.0})\n",
    "\n",
    "        # Save Loss Curve\n",
    "        plt.figure()\n",
    "        plt.plot(losses, label='Training Loss')\n",
    "        plt.title(f'Loss Curve ({act_name})')\n",
    "        plt.savefig(f\"{output_dir}/loss_{act_name}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Save Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, final_test_preds)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "        plt.title(f'Confusion Matrix ({act_name})')\n",
    "        plt.savefig(f\"{output_dir}/conf_matrix_{act_name}.png\")\n",
    "        plt.close()\n",
    "\n",
    "        # Save Results to PDF\n",
    "        pdf.add_page()\n",
    "        pdf.set_font(\"Arial\", size=12)\n",
    "        pdf.multi_cell(0, 10, f\"Activation Function: {act_name}\")\n",
    "        pdf.multi_cell(0, 10, f\"Hidden Layer Size: {hidden_size}\")\n",
    "        pdf.multi_cell(0, 10, f\"Final Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "        pdf.multi_cell(0, 10, f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "\n",
    "        pdf.image(f\"{output_dir}/loss_{act_name}.png\", x=10, y=60, w=100)\n",
    "        pdf.image(f\"{output_dir}/conf_matrix_{act_name}.png\", x=10, y=180, w=100)\n",
    "\n",
    "# Save PDF Report\n",
    "pdf_output_path = os.path.join(output_dir, \"MNIST_Results_Report.pdf\")\n",
    "pdf.output(pdf_output_path)\n",
    "print(f\"\\nPDF Report saved successfully at: {pdf_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
